{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Rameez Nizar/Miniconda3/Capstone Project Data/Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df1=df[df['Score']>3]\n",
    "df2=df[df['Score']<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443777, 10)\n",
      "(82037, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_filtered=df1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 10)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_filtered['Sentiment'] = np.where(df_filtered.Score<3, 'Negative','Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_new=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 1)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['Trimmed_Text']=df_filtered.loc[:,'Text'].str.slice(0,500)\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_filtered_final=pd.concat([df_filtered.reset_index(drop=True), df_new.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 12)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trimmed_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This saltwater taffy had great flavors and was...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Trimmed_Text Sentiment\n",
       "0  I have bought several of the Vitality canned d...  Positive\n",
       "1  This is a confection that has been around a fe...  Positive\n",
       "2  Great taffy at a great price.  There was a wid...  Positive\n",
       "3  I got a wild hair for taffy and ordered this f...  Positive\n",
       "4  This saltwater taffy had great flavors and was...  Positive"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_final=df_filtered_final[['Trimmed_Text','Sentiment']]\n",
    "df_filtered_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#tuples = [tuple(x) for x in df_filtered_final.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#To remove speical characters\n",
    "df_filtered_final['Special_Chars_Removed']=df_filtered_final['Trimmed_Text'].str.replace('[^A-Za-z\\s]+','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#To remove numbers from string\n",
    "df_filtered_final['Special_Chars_Removed'] = df_filtered_final['Special_Chars_Removed'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Removing underscore\n",
    "df_filtered_final['Special_Chars_Removed']=df_filtered_final.Special_Chars_Removed.str.replace('_','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Converting everything into lower\n",
    "df_filtered_final['Special_Chars_Removed']=df_filtered_final.Special_Chars_Removed.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_filtered_final['Special_Chars_Removed'] = df_filtered_final.Special_Chars_Removed.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentences = df_filtered_final['Special_Chars_Removed'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=nltk.tag.pos_tag(['started'])\n",
    "get_wordnet_pos(l[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than most',\n",
       " 'this is a confection that has been around a few centuries it is a light pillowy citrus gelatin with nuts in this case filberts and it is cut into tiny squares and then liberally coated with powdered sugar and it is a tiny mouthful of heaven not too chewy and very flavorful i highly recommend this yummy treat if you are familiar with the story of cs lewis the lion the witch and the wardrobe this is the treat that seduces edmund into selling out his brother and sisters to t']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences=sentences[0:2]\n",
    "sentences\n",
    "\n",
    "#for i in (range(len(sentences))):\n",
    "          #print(sentences[i])\n",
    "        #print(nltk.pos_tag(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "[('i', 'NN')]\n",
      "i\n",
      "have\n",
      "[('have', 'VB')]\n",
      "have\n",
      "bought\n",
      "[('bought', 'NN')]\n",
      "bought\n",
      "several\n",
      "[('several', 'JJ')]\n",
      "several\n",
      "of\n",
      "[('of', 'IN')]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-191-a3c7c18d0257>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlmtzr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mget_wordnet_pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Rameez Nizar\\Miniconda3\\envs\\cse801\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Rameez Nizar\\Miniconda3\\envs\\cse801\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36m_morphy\u001b[1;34m(self, form, pos)\u001b[0m\n\u001b[0;32m   1685\u001b[0m         \u001b[1;31m#    find a match or you can't go any further\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1687\u001b[1;33m         \u001b[0mexceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1688\u001b[0m         \u001b[0msubstitutions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMORPHOLOGICAL_SUBSTITUTIONS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "        l=sentences[i].split(\" \")\n",
    "        for j in range(len(l)):\n",
    "            print(l[j])\n",
    "            t=nltk.tag.pos_tag([l[j]])\n",
    "            print(t)\n",
    "            print(lmtzr.lemmatize(l[j],get_wordnet_pos(t[0][1])))\n",
    "            \n",
    "            \n",
    "            #t=nltk.tag.pos_tag([l[j]])\n",
    "            #print(t)\n",
    "            #print(lmtzr.lemmatize(l[j],get_wordnet_pos(t[0][1])))\n",
    "            \n",
    "            \n",
    "            \n",
    "           # print(lmtzr.lemmatize(l[j])\n",
    "            \n",
    "            #print(lmtzr(l[j],get_wordnet_pos(nltk.pos_tag(l[j]))))\n",
    "            \n",
    "        \n",
    "        #text=nltk.tokenize.word_tokenize(i)\n",
    "        #\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a confection that has been around a few centuries  it is a light pillowy citrus gelatin with nuts  in this case filberts and it is cut into tiny squares and then liberally coated with powdered sugar  and it is a tiny mouthful of heaven  not too chewy and very flavorful  i highly recommend this yummy treat  if you are familiar with the story of cs lewis the lion the witch and the wardrobe  this is the treat that seduces edmund into selling out his brother and sisters to t'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525814"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_words=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for words in range(len(sentences)):\n",
    "    new_words.append(sentences[words].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#from nltk.stem import WordNetLemmatizer\n",
    "#lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#lemmatized_words=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paid', 'paying', 'pay', 'presumably', 'owed', 'say']\n"
     ]
    }
   ],
   "source": [
    "#typea = ['paid', 'paying', 'pays', 'presumably', 'owed', 'says']\n",
    "#lemmatized_words = [lmtzr.lemmatize(x) for x in typea]\n",
    "#print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#final=list()\n",
    "#final_words=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#for i in new_words:\n",
    "    #final=list()\n",
    "    #for j in i:\n",
    "        #final.append(lmtzr.lemmatize(j))\n",
    "    #final_words.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525814"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#remove_gib=list()\n",
    "#remove_gib_final=list()\n",
    "#del(remove_gib)\n",
    "#del(remove_gib_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#for i in final_words:\n",
    "    #remove_gib=list()\n",
    "    #for j in i:\n",
    "        #if j in words.words():\n",
    "            #remove_gib.append(j)\n",
    "    #remove_gib_final.append(remove_gib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Need to run this after that step\n",
    "for str2 in remove_gib:\n",
    "    str1 = ' '.join(str2)\n",
    "    cleaned_text.append(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trimmed_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Special_Chars_Removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>great taffy at a great price  there was a wide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>i got a wild hair for taffy and ordered this f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This saltwater taffy had great flavors and was...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>this saltwater taffy had great flavors and was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Trimmed_Text Sentiment  \\\n",
       "0  I have bought several of the Vitality canned d...  Positive   \n",
       "1  This is a confection that has been around a fe...  Positive   \n",
       "2  Great taffy at a great price.  There was a wid...  Positive   \n",
       "3  I got a wild hair for taffy and ordered this f...  Positive   \n",
       "4  This saltwater taffy had great flavors and was...  Positive   \n",
       "\n",
       "                               Special_Chars_Removed  \n",
       "0  i have bought several of the vitality canned d...  \n",
       "1  this is a confection that has been around a fe...  \n",
       "2  great taffy at a great price  there was a wide...  \n",
       "3  i got a wild hair for taffy and ordered this f...  \n",
       "4  this saltwater taffy had great flavors and was...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trimmed_Text</th>\n",
       "      <th>Special_Chars_Removed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>82037</td>\n",
       "      <td>82037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>443777</td>\n",
       "      <td>443777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Trimmed_Text  Special_Chars_Removed\n",
       "Sentiment                                     \n",
       "Negative          82037                  82037\n",
       "Positive         443777                 443777"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_final.groupby('Sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#from textblob.classifiers import NaiveBayesClassifier\n",
    "#>>>cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Bag of words\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#count_vect = CountVectorizer(lowercase=True,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#x = count_vect.fit_transform(df_filtered_final['Trimmed_Text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 99669)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 99669)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tf_transformer = TfidfTransformer(use_idf=False).fit(x)\n",
    "#X_train_tf = tf_transformer.transform(x)\n",
    "#X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Tf-Idf\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<525814x99669 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12447936 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#v = TfidfVectorizer(lowercase=True,stop_words='english')\n",
    "#x = v.fit_transform(df_filtered_final['Trimmed_Text'].values.astype('U'))\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 99669)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#clf = MultinomialNB().fit(X_train_tf, df_filtered_final['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#docs_new = ['food was awesome', 'The taste was bad','extremely bad','awful','it was disgraceful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#X_new_counts = count_vect.transform(docs_new)\n",
    "#X_new_tfidf = tf_transformer.transform(X_new_counts)\n",
    "#predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', 'Negative', 'Negative'], \n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Using test-train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_filtered_final['Special_Chars_Removed'],df_filtered_final['Sentiment'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_train))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk import word_tokenize     \n",
    "#nltk.download()\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "vect = CountVectorizer(lowercase=True,tokenizer=LemmaTokenizer(),stop_words='english',ngram_range=(1,2),min_df = 5 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368069, 348860)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = vect.fit_transform(X_train.values.astype('U'))\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(x)\n",
    "X_train_tf = tf_transformer.transform(x)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157745, 348860)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = vect.transform(X_test.values.astype('U'))\n",
    "X_test_tf = tf_transformer.transform(x_test)\n",
    "X_test_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90808788569534515"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_tf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8236,  16527],\n",
       "       [   267, 132715]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>8236</td>\n",
       "      <td>16527</td>\n",
       "      <td>24763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>267</td>\n",
       "      <td>132715</td>\n",
       "      <td>132982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>8503</td>\n",
       "      <td>149242</td>\n",
       "      <td>157745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Positive     All\n",
       "True                                 \n",
       "Negative       8236     16527   24763\n",
       "Positive        267    132715  132982\n",
       "All            8503    149242  157745"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def most_informative_feature_for_binary_classification(vectorizer, classifier, n=30):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "\n",
    "    for coef, feat in topn_class1:\n",
    "        print (class_labels[0], coef, feat)\n",
    "\n",
    "    print\n",
    "\n",
    "    for coef, feat in reversed(topn_class2):\n",
    "        print(class_labels[1], coef, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative -15.1469496793 aa hrefhttpww\n",
      "Negative -15.1469496793 aa hrefhttpwwwamazoncomgpproductbilkumkernel\n",
      "Negative -15.1469496793 aa hrefhttpwwwamazoncomgpproductbpgjicswiss\n",
      "Negative -15.1469496793 aa medium\n",
      "Negative -15.1469496793 aa preservativeoh\n",
      "Negative -15.1469496793 aa wa\n",
      "Negative -15.1469496793 aa year\n",
      "Negative -15.1469496793 aaaaawhere startwfood\n",
      "Negative -15.1469496793 aaah gluten\n",
      "Negative -15.1469496793 aachen munich\n",
      "Negative -15.1469496793 aafco compliance\n",
      "Negative -15.1469496793 aafco regulation\n",
      "Negative -15.1469496793 aamazoncom stand\n",
      "Negative -15.1469496793 aamzonbr br\n",
      "Negative -15.1469496793 aand actually\n",
      "Negative -15.1469496793 aap say\n",
      "Negative -15.1469496793 aauces shelf\n",
      "Negative -15.1469496793 ab food\n",
      "Negative -15.1469496793 ab understanding\n",
      "Negative -15.1469496793 aback flavor\n",
      "Negative -15.1469496793 aback foreign\n",
      "Negative -15.1469496793 aback potency\n",
      "Negative -15.1469496793 aback presence\n",
      "Negative -15.1469496793 aback smell\n",
      "Negative -15.1469496793 abalone like\n",
      "Negative -15.1469496793 abalone want\n",
      "Negative -15.1469496793 abandon healthy\n",
      "Negative -15.1469496793 abandoned apartment\n",
      "Negative -15.1469496793 abandoned bean\n",
      "Negative -15.1469496793 abandoned boneand\n",
      "Positive -7.72364425439 taste great\n",
      "Positive -7.75881347304 taste like\n",
      "Positive -7.78363522249 grocery store\n",
      "Positive -7.82757872664 highly recommend\n",
      "Positive -7.84108218298 dog love\n",
      "Positive -7.9879615478 ive tried\n",
      "Positive -8.00140831911 taste good\n",
      "Positive -8.04919018245 great product\n",
      "Positive -8.1035576573 peanut butter\n",
      "Positive -8.10969235347 gluten free\n",
      "Positive -8.20280861924 just right\n",
      "Positive -8.20863722659 green tea\n",
      "Positive -8.20949299309 year old\n",
      "Positive -8.21321406206 dog food\n",
      "Positive -8.24180715188 really good\n",
      "Positive -8.26499415518 really like\n",
      "Positive -8.30093042462 cup coffee\n",
      "Positive -8.3579318095 great price\n",
      "Positive -8.47291322649 just like\n",
      "Positive -8.59886819134 cat food\n",
      "Positive -8.6015073775 year ago\n",
      "Positive -8.61108848811 wa good\n",
      "Positive -8.61299375946 subscribe save\n",
      "Positive -8.64583154259 great taste\n",
      "Positive -8.65972007146 wa great\n",
      "Positive -8.68112393655 great flavor\n",
      "Positive -8.69818704419 absolutely love\n",
      "Positive -8.71716775959 local store\n",
      "Positive -8.74151104238 long time\n",
      "Positive -8.75498633934 dont know\n"
     ]
    }
   ],
   "source": [
    "most_informative_feature_for_binary_classification(vect,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#a=df_filtered_final['Special_Chars_Removed'][df_filtered_final['Special_Chars_Removed'].str.contains(\"_\")].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "Playing\n",
      "Player\n",
      "Plays\n",
      "Play\n",
      "Plays\n"
     ]
    }
   ],
   "source": [
    "print(lmtzr.lemmatize(\"cats\",'v'))\n",
    "print(lmtzr.lemmatize(\"Playing\",'n'))\n",
    "print(lmtzr.lemmatize(\"Player\",'v'))\n",
    "print(lmtzr.lemmatize(\"Plays\",'v'))\n",
    "print(lmtzr.lemmatize(\"Play\",'v'))\n",
    "print(lmtzr.lemmatize(\"Plays\",'v'))\n",
    "\n",
    "\n",
    "#print(lmtzr.lemmatize(\"better\", pos=\"a\"))\n",
    "#print(lmtzr.lemmatize(\"best\", pos=\"a\"))\n",
    "#print(lmtzr.lemmatize(\"run\"))\n",
    "#print(lmtzr.lemmatize(\"run\",'v'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "s = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model=s.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.score(X_train_tf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_predicted = model.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,model_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('We', 'PRP'), ('are', 'VBP'), ('going', 'VBG'), ('out.Just', 'IN'), ('you', 'PRP'), ('and', 'CC'), ('me', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "text=nltk.word_tokenize(\"We are going out.Just you and me.\")\n",
    "print(nltk.pos_tag(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
